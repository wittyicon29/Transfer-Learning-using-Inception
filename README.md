# Transfer-Learning-using-Inception
Transfer learning is a machine learning technique where a model trained on one task is re-purposed on a second related task. Inception is a deep convolutional neural network architecture that was developed for image classification. Transfer learning using Inception typically involves using a pre-trained Inception model as a starting point and then fine-tuning the model on the new task using a smaller dataset.
The main advantage of using transfer learning is that it can significantly reduce the amount of data and computation required to train a new model. This is because the pre-trained model has already learned many of the features and patterns that are useful for the new task, so the new model can focus on learning the differences between the new task and the original task. This can be especially helpful when the dataset for the new task is small or when the new task is similar to the original task.
Using transfer learning with the Inception architecture in this way can help the model learn to classify horses and humans more accurately, as the model has already learned many of the features and patterns that are useful for image classification. This can significantly reduce the amount of data and computation required to train a new model from scratch, and can lead to improved performance on the new task compared to training a model from scratch.
